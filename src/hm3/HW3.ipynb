{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework III\n",
    "\n",
    "Joana Peixinho (ist1103335) & Miguel Fernandes (ist1103573)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Pen and Paper [12v]\n",
    "\n",
    "For questions in this group, show your numerical results with 5 decimals or scientific notation.\n",
    "Hint: we highly recommend the use of numpy (e.g., linalg.pinv for inverse) or other programmatic\n",
    "facilities to support the calculus involved in both questions (1) and (2).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Consider the problem of learning a regression model from 4 bivariate observations{(0.7‚àí0.3) , (0.40.5) , (‚àí0.20.8) , (‚àí0.40.3)} with targets (0.8, 0.6, 0.3, 0.3).\n",
    "\n",
    "**a.) . [4v] Given the radial basis function, ùúôùëó(ùë•) = ùëíùë•ùëù (‚àí(‚Äñùê±‚àíùíÑùëó‚Äñ^2)/2), that transforms the original space onto a new space characterized by the similarity of the original observations to the following data points, {ùíÑ1 = (0,0) , ùíÑ2 = (1,‚àí1) , ùíÑ3 = (‚àí1,1)}. Learn the Ridge regression (ùëô2 regularization) using the closed solution with ùúÜ = 0.1.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Given data\n",
    "observations = np.array([[0.7, -0.3], [0.4, 0.5], [-0.2, 0.8], [-0.4, 0.3]])\n",
    "targets = np.array([0.8, 0.6, 0.3, 0.3])\n",
    "c_points = np.array([[0, 0], [1, -1], [-1, 1]])\n",
    "Œª = 0.1\n",
    "\n",
    "# Step 1: Compute radial basis function features\n",
    "def radial_basis_function(x, c):\n",
    "    return np.exp(-np.linalg.norm(x - c)**2 / 2)\n",
    "\n",
    "phi = np.array([[radial_basis_function(x, c) for c in c_points] for x in observations])\n",
    "\n",
    "# Include a column of ones for the bias term in the feature matrix\n",
    "X = np.hstack((np.ones((observations.shape[0], 1)), phi))\n",
    "\n",
    "# Step 2: Set up Ridge regression problem\n",
    "y = targets.reshape(-1, 1)\n",
    "\n",
    "# Step 3: Solve for weights\n",
    "I = np.identity(X.shape[1])\n",
    "w = np.linalg.inv(X.T @ X + Œª*I) @ X.T @ y\n",
    "\n",
    "# Extract the bias term w0\n",
    "w0 = w[0, 0]\n",
    "\n",
    "# Extract the other weights (w1, w2, ..., wn)\n",
    "weights = w[1:]\n",
    "\n",
    "# Print the weights\n",
    "print(\"Matrix X:\")\n",
    "print(np.around(X, decimals=5))\n",
    "print(\"Vector y:\")\n",
    "print(y)\n",
    "print(\"Weights:\")\n",
    "print(np.around(w, decimals=5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b.) [2v] Compute the training RMSE for the learnt regression.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Root Mean Square Error\n",
    "y_pred = X @ w\n",
    "RMSE = np.sqrt(np.mean((y - y_pred)**2))\n",
    "print(\"Predicted targets:\")\n",
    "print(np.around(y_pred, decimals=5))\n",
    "print(\"RMSE:\", np.around(RMSE, decimals=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) [6v] Consider a MLP classifier of three outcomes ‚Äì ùê¥, ùêµ and ùê∂ ‚Äì characterized by the weights.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Rest of the Exercise](./I_2_exercise.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming [8v]\n",
    "\n",
    "**Consider the winequality-red.csv dataset (available at the webpage) where the goal is to estimate\n",
    "the quality (sensory appreciation) of a wine based on physicochemical inputs.\n",
    "Using a 80-20 training-test split with a fixed seed (random_state=0), you are asked to learn MLP\n",
    "regressors to answer the following questions.\n",
    "Given their stochastic behavior, average the performance of each MLP from 10 runs\n",
    "(for reproducibility consider seeding the MLPs with random_state ‚àà {1. .10}).**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"winequality-red.csv\", sep=\";\")\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train, test = train_test_split(data, test_size=0.2, random_state=0)\n",
    "\n",
    "# Split the dataset into features (X) and target variable (y) for both training and testing sets\n",
    "X_train = train.drop(columns=['quality'])\n",
    "y_train = train['quality']\n",
    "X_test = test.drop(columns=['quality'])\n",
    "y_test = test['quality']\n",
    "\n",
    "# Standardize the features using the same scaler for consistency\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) [3.5v]\n",
    "\n",
    "**Learn a MLP regressor with 2 hidden layers of size 10, rectifier linear unit activation\n",
    "on all nodes, and early stopping with 20% of training data set aside for validation. All\n",
    "remaining parameters (e.g., loss, batch size, regularization term, solver) should be set as\n",
    "default. Plot the distribution of the residues (in absolute value) using a histogram.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(10, 10), activation='relu', early_stopping=True, validation_fraction=0.2, random_state=0)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "y_pred = mlp.predict(X_test)\n",
    "residuals = np.abs(y_test - y_pred)\n",
    "\n",
    "plt.hist(residuals, bins=20, edgecolor='k')\n",
    "plt.title(\"Distribution of Residuals\")\n",
    "plt.xlabel(\"Residual (Absolute Value)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) [1.5v]\n",
    "\n",
    "**Since we are in the presence of a integer regression task, a recommended trick is to\n",
    "round and bound estimates. Assess the impact of these operations on the MAE of the MLP\n",
    "learnt in previous question.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) [1.5v]\n",
    "\n",
    "**Similarly assess the impact on RMSE from replacing early stopping by a well-defined\n",
    "number of iterations in {20,50,100,200} (where one iteration corresponds to a batch).**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miguel/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/miguel/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/miguel/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/miguel/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/miguel/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/miguel/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/miguel/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/miguel/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/miguel/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/miguel/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/miguel/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/miguel/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/miguel/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/miguel/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/miguel/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/miguel/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/miguel/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/miguel/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/miguel/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/miguel/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/miguel/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/miguel/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/miguel/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/miguel/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/miguel/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/miguel/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/miguel/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/miguel/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/miguel/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/miguel/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/miguel/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/miguel/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/miguel/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/miguel/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/miguel/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/miguel/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/miguel/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/miguel/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/miguel/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for 20 iterations: 1.615488865622505\n",
      "RMSE for 50 iterations: 1.137606992557196\n",
      "RMSE for 100 iterations: 0.8595049512642285\n",
      "RMSE for 200 iterations: 0.6743820374166419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miguel/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def train_mlp_with_iterations(num_iterations):\n",
    "    rmse_sum = 0\n",
    "    for random_i in range(1,11):\n",
    "        \n",
    "        mlp = MLPRegressor(max_iter=num_iterations, random_state=random_i)\n",
    "        mlp.fit(X_train, y_train)\n",
    "    \n",
    "        y_pred = mlp.predict(X_test)\n",
    "        rmse_sum += np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    \n",
    "    return rmse_sum/10\n",
    "\n",
    "iteration_values = [20, 50, 100, 200]\n",
    "\n",
    "rmse_values = []\n",
    "\n",
    "for num_iterations in iteration_values:\n",
    "    rmse = train_mlp_with_iterations(num_iterations)\n",
    "    rmse_values.append(rmse)\n",
    "\n",
    "# Print the RMSE values for different numbers of iterations\n",
    "for i, num_iterations in enumerate(iteration_values):\n",
    "    print(f'RMSE for {num_iterations} iterations: {rmse_values[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) [1.5v]\n",
    "\n",
    "**Critically comment the results obtained in previous question, hypothesizing at least\n",
    "one reason why early stopping favors and/or worsens performance.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, as the number of training iterations increases, the RMSE decreases, which is a positive sign. Lower RMSE values suggest that the model is improving its ability to predict the target variable more accurately. It's important to monitor the RMSE during training to assess the model's convergence and to determine when it reaches a point of diminishing returns or starts to overfit the data.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
